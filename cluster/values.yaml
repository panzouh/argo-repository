---
# General

default:
  # -- Enable default charts (ArgoCD)
  enabled: false
  # -- Define storageClass in order to persistence to work
  storageClass: ""
  # -- Claims type can be either `RWO` or `RWX`, storageClass needs to be enabled
  accessModes: RWO
  # -- Smtp server to configure notifications :warning: not working yet :warning:
  smtpServer: "0.0.0.0:25"

# -- If you want to do some debug you can modify the [debug-file](./templates/debug-tpl.yml) template to try some of your functions
debug: false

sync:
  # -- Allow you to activate auto-sync w/ selfHeal & prune mecanism
  enabled: true
  # -- y default changes that are made to the live cluster will not trigger automated sync. This variable allow to enable automatic sync when the live cluster's state deviates from the state defined in Git
  selfHeal: true
  # -- By default (and as a safety mechanism), automated sync will not delete resources but on this chart it is enabled by default
  prune: true

proxies:
  # -- Enable proxy support for all charts
  enabled: false
  # -- Define http(s) proxy
  value: ""
  # -- Define noProxy value should be `noProxy: .cluster.local,.svc,podsCIDR,svcCIDR`
  noProxy: ""

# Backup

velero:
  # -- Enable Velero chart
  enabled: false
  # -- Destination namespace
  namespace: velero-system
  chart:
    # -- Helm repository
    repo: https://vmware-tanzu.github.io/helm-charts
    # -- Chart name
    name: velero
    # -- Chart version
    version: "2.30.2"
  values:
    # -- Enable prometheus metrics scraping, you will need to enable Prometheus as well
    monitor: false
    # -- Provider type can be aws, gcp or azure
    provider: aws
    # -- Provider image tag
    # [AWS](https://hub.docker.com/r/velero/velero-plugin-for-aws/tags)
    # [GCP](https://hub.docker.com/r/velero/velero-plugin-for-gcp/tags)
    # [Azure](https://hub.docker.com/r/velero/velero-plugin-for-microsoft-azure/tags)
    tag: v1.5.0
    # -- cloudSecretContent, watch value file for examples
    cloudSecretContent: ""
    # [AWS](https://github.com/vmware-tanzu/velero-plugin-for-aws/blob/main/README.md)
    # [GCP](https://github.com/vmware-tanzu/velero-plugin-for-gcp/blob/main/README.md)
    # [Azure](https://github.com/vmware-tanzu/velero-plugin-for-microsoft-azure/blob/main/README.md)
    backupStorageLocation:
      # -- name is the name of the backup storage location where backups should be stored. If a name is not provided,    # a backup storage location will be created with the name "default". Optional
      name: default
      # -- bucket is the name of the bucket to store backups in. Required.
      bucket: backups
      # -- region is the region of the bucket. Required
      region: eu-west-3
    volumeSnapshotLocation:
      # -- name is the name of the backup storage location where backups should be stored. If a name is not provided,    # a backup storage location will be created with the name "default". Optional
      name: default
      # -- region is the region of the bucket. Required
      region: eu-west-3

# Data

data:
  # -- Data installation namespace
  namespace: data
  airbyte:
    # -- Enabe Airbyte chart
    enabled: false
    chart:
      # -- Helm repository
      repo: https://airbytehq.github.io/helm-charts/
      # -- Chart name
      name: airbyte
      # -- Chart version
      version: "0.42.0"

# Integration

argocd:
  # -- Enable ArgoCD chart
  enabled: false
  # -- Destination namespace & Applications source namespace
  namespace: argocd
  chart:
    # -- Helm repository
    repo: https://argoproj.github.io/argo-helm
    # -- Chart name
    name: argo-cd
    # -- Chart version
    version: "5.14.0"
  values:
    # -- Application controller logLevel
    logLevel: debug
    # -- Enable Helm alternate plugin `helm upgrade --install` instead of `helm template . | kubectl apply -f -`
    enableAlternateHelmPlugin: false
    plugins:
      avp:
        # -- Enable AVP extension, watch [AVP Documention](../docs/security/avp-documention.md) first
        enabled: false
        # -- Tell to Argo which SA to create
        saName: avp
        # -- AVP version to install
        version: "1.11.0"
        auth:
          # -- Only if `argocd.values.avp.enabled=true` & `vault.enabled=false` for external Vault support only
          vaultUrl: "https://your-vault.domain.tld"
          # -- AVP auth type
          type: k8s
          # AVP auth path
          path: auth/kubernetes
      gzip:
        # -- Enable gzip
        enabled: false
      alp:
        # -- Enable Argo Lovely Plugin extension
        enabled: false
        # -- Enable Argo Lovely Plugin version to install
        version: stable
    # -- Enable prometheus metrics scraping, you will need to enable Prometheus as well
    monitor: false
    # -- Enable ArgoCD on HA mode
    ha: true
    ingress:
      # -- Enable ArgoCD UI ingress
      enabled: true
      # -- ArgoCD ingress name or path (weither it is an ingress wildcard or domain
      name: argocd
    # -- Enable ArgoCD all the way TLS, will be deactivated if ingress are enabled
    insecure: false
    # -- Registered repositories, watch section below :warning: Credentials creation not handled yet :warning:
    repositories: []

customCatalogs:
  # -- Enable custom catalog sources, you will need to enable OLM
  enabled: false
  # -- Destination namespace
  namespace: olm
  chart:
    # -- Helm repository (This own repository)
    repo: https://github.com/panzouh/argo-repository.git
    # -- Chart path on repository
    path: charts/custom-catalogs
    # -- Chart target revision, using `HEAD` allow you to use the same version of your cluster spec
    targetRevision: HEAD
  values:
    # -- OLM namespace
    olmNamespace: olm
    # -- Custom catalogs definition, watch section bellow
    catalogs: []
    # -- Subscriptions definition, watch section bellow
    subscriptions: []

argoEvents:
  # -- Enable Argo Events chart
  enabled: false
  # -- Destination namespace
  namespace: argo-events
  chart:
    # -- Helm repository
    repo: https://argoproj.github.io/argo-helm
    # -- Chart name
    name: argo-events
    # -- Chart version
    version: 2.0.8
  values: {}

argoWorkflows:
  # -- Enable Argo Workflows chart
  enabled: false
  # -- Destination namespace
  namespace: argo-workflows
  chart:
    # -- Helm repository
    repo: https://argoproj.github.io/argo-helm
    # -- Chart name
    name: argo-workflows
    # -- Chart version
    version: 0.22.1
  values:
    ingress:
      # -- Enable Argo workflows UI ingress
      enabled: true
      # -- Argo workflows ingress name or path (weither it is an ingress wildcard or domain)
      name: argo-workflows

externalCharts:
  chart:
    # -- Helm repository (This own repository)
    repo: https://github.com/panzouh/argo-repository.git
    # -- Chart path on repository
    path: charts/external-charts
    # -- Chart target revision, using `HEAD` allow you to use the same version of your cluster spec
    # -- Chart target revision, using `HEAD` allow you to use the same version of your cluster spec
    targetRevision: HEAD
  values:
    # -- Registered repositories, watch section below :warning: Credentials creation not handled yet :warning:
    charts: []
    # - name: test
    #   namespace: test
    #   repo: https://test.git
    #   type: git
    #   path: charts/test
    #   cName: test
    #   targetRevision: HEAD
    #   values:
    #     debug: true

gitlabRunners:
  chart:
    # -- Gitlab runners Helm repository
    repo: https://charts.gitlab.io
    # -- Chart name
    name: gitlab-runner
    # -- Chart version
    version: 0.42.0
  values:
    # -- Create runners watch section below
    runners: []

harbor:
  # -- Enable Harbor repository chart, you will need to enable Traefik or Nginx as well
  enabled: false
  # -- Destination namespace
  namespace: harbor-system
  chart:
    # -- Helm repository
    repo: https://helm.goharbor.io
    # -- Chart name
    name: harbor
    # -- Chart version
    version: 1.9.2
  values:
    # -- Enable prometheus metrics scraping, you will need to enable Prometheus as well
    monitor: false
    # -- Initial admin user password if the application is exposed consider changing it
    bootstrapPassword: changeme
    # -- The secret key used for encryption. Must be a string of 16 chars.
    secretKey: not-a-secure-key
    persitence:
      # -- Registry PVC size, you will need to define a StorageClass in `default.storageClass`
      registry: 50Gi
      # -- Chartmuseum PVC size, you will need to define a StorageClass in `default.storageClass`
      chartmuseum: 10Gi
      # -- Jobservice PVC size, you will need to define a StorageClass in `default.storageClass`
      jobservice: 2Gi
      # -- Database PVC size, you will need to define a StorageClass in `default.storageClass`
      database: 8Gi
      # -- Redis PVC size, you will need to define a StorageClass in `default.storageClass`
      redis: 2Gi
      # -- Trivy PVC size, you will need to define a StorageClass in `default.storageClass`
      trivy: 5Gi
    ingress:
      # -- Enable Harbor ingresses
      enabled: true
      # -- Harbor core ingress name or path (weither it is an ingress wildcard or domain)
      coreName: core
      # -- Harbor notary ingress name or path (weither it is an ingress wildcard or domain)
      notaryName: notary

namespaceConfiguratorOperator:
  # -- Enable Namespace configuration operator chart, you will need to enable Certmanager as well
  enabled: false
  # -- Destination namespace
  namespace: namespace-configuration
  chart:
    # -- Helm repository
    repo: https://redhat-cop.github.io/namespace-configuration-operator
    # -- Chart name
    name: namespace-configuration-operator
    # -- Chart version
    version: v1.2.4
  values:
    # -- Enable prometheus metrics scraping, you will need to enable Prometheus as well
    monitor: false

namespaceConfiguration:
  # -- Enable Namespace configuration chart
  enabled: false
  # -- Destination namespace
  namespace: namespace-configurator
  chart:
    # -- Helm repository (This own repository)
    repo: https://github.com/panzouh/argo-repository.git
    # -- Chart path on repository
    path: charts/namespace-configuration
    # -- Chart target revision, using `HEAD` allow you to use the same version of your cluster spec
    targetRevision: HEAD
  values:
    # -- Create *n* resources quotas so your users does not overconsume compute resources
    quotas: []
    # -- Create *n* network policies
    networkPolicies: []
    isolatedNetworkPolicy:
      # -- Create the isolated networkPolicy (Full access on current namespace, access outside the cluster, accessible by ingress & monitoring, restricted to every other namespaces)
      enabled: false
      # -- You will need to specify podCIDR & serviceCIDR you can get it by running `kubectl cluster-info dump | grep -m 1 service-cluster-ip-range` & `kubectl cluster-info dump | grep -m 1 cluster-cidr`
      clusterCIDRs: []

olm:
  # -- Enable OLM chart
  enabled: false
  # -- Destination namespace
  namespace: olm
  chart:
    # -- Helm repository (This own repository)
    repo: https://github.com/panzouh/argo-repository.git
    # -- Chart path on repository
    path: charts/olm-manifests
    # -- Chart target revision, using `HEAD` allow you to use the same version of your cluster spec
    targetRevision: HEAD
  values: {}

# Logging

logging:
  loki:
    # -- Enable Loki chart
    enabled: true
    chart:
      # -- Helm repository
      repo: https://grafana.github.io/helm-charts
      # -- Chart name
      name: loki
      # -- Chart version
      version: "3.8.0"
    values:
      # -- Enable prometheus metrics scraping, you will need to enable Prometheus as well
      monitor: false
      # -- Loki PVC size, you will need to define a StorageClass in `default.storageClass`
      pvcSize: 50Gi
      # -- Enable a Grafana specific dashboard, you will need to have Grafana enabled
      enableGrafanaDashboard: true
      # -- Loki retention
      retention: 740h
      ingress:
        # -- Enable Kibana UI Ingress
        enabled: true
        # -- Loki ingress name or path (weither it is an ingress wildcard or domain)
        name: loki
      # -- Node tolerations for scheduling Loki to nodes with taints [Kubernetes Documentation](https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/)
      tolerations: []
      # -- Node labels for Loki pod assignment
      nodeSelector: {}

  promtail:
    # -- Enable Promtail chart
    enabled: false
    chart:
      # -- Helm repository
      repo: https://grafana.github.io/helm-charts
      # -- Chart name
      name: promtail
      # -- Chart version
      version: "6.0.2"
    values:
      # -- Enable Promtail on the controll plane
      installOnControllPlane: true
      # -- Path to runtime containers
      runtimeLogs: "/var/log/containers"
      # -- Extra volumes to be added in addition to those specified by default
      extraVolumes: []
      # -- Extra volume mounts together. Corresponds to `extraVolumes`.
      extraVolumeMounts: []
      # -- Enable extra configuration scrapes in the, watch section bellow for examples
      extraScrapeConfigs: []
      # -- Enable extra configuration relabels in the, watch section bellow for examples
      extraRelabelConfigs: []

  eck:
    # -- Enable ECK chart, installing [OLM](https://github.com/operator-framework/operator-lifecycle-manager) is mandantory
    enabled: false
    chart:
      # -- Helm repository
      repo: https://helm.elastic.co
      # -- Chart name
      name: eck-operator
      # -- Chart version
      version: "2.3.0"
    values:
      # -- Filter namespaces to watch you can leave it empty to watch all namespaces
      watchNamespaces:
        - elastic-system
      # -- Enable telemetry
      telemetryEnabled: true
      # -- Operator verbosity
      verbosity: warning
      # -- Enable prometheus metrics scraping, you will need to enable Prometheus as well
      monitor: false
  eckCrds:
    chart:
      # -- Helm repository
      repo: https://helm.elastic.co
      # -- Chart name
      name: eck-operator-crds
      # -- Chart version
      version: "2.3.0"
    # -- No specific values needs to be specified
    values: {}
  eckTpl:
    # -- Enable ECK Tpl chart
    enabled: false
    chart:
      # -- Helm repository (This own repository)
      repo: https://github.com/panzouh/argo-repository.git
      # -- Chart path
      path: charts/eck-tpl
      # -- Chart target revision, using `HEAD` allow you to use the same version of your cluster spec
      targetRevision: HEAD
    values:
      clusterSpec:
        # -- ECK Cluster name
        name: eck-cluster
        # -- ECK Cluster version
        version: 8.2.0
        elasticsearch:
          # -- Elasticsearch instance count
          count: 3
          # -- Elasticsearch configuration
          config: {}
          # -- Elasticsearch service type can be either `Loadbalancer`, `ClusterIP` or `NodePort`
          serviceType: ClusterIP
          # -- Elasticsearch PVC size, you will need to define a StorageClass in `default.storageClass`
          pvcSize: 50Gi
          tls:
            # -- Enable TLS Generation
            enabled: true
            # -- To use a custom domain name and / or IP with the self-signed certificate `clusterSpec.elasticsearch.serviceType` must be `LoadBalancer` & must be not empty
            subjectAltNames: []
        kibana:
          # -- Kibana instance count
          count: 1
          # -- Kibana configuration
          config: {}
          ingress:
            # -- Enable Kibana UI Ingress
            enabled: true
            # -- Kibana ingress name or path (weither it is an ingress wildcard or domain)
            name: kibana
        filebeat:
          # -- Enable Filebeat instances
          enabled: false
          # -- Set Filebeat mounts
          mounts: []
          config: {}

# Management

rancher:
  # -- Enable Rancher chart
  enabled: false
  # -- Destination namespace
  namespace: cattle-system
  chart:
    # -- Helm repository
    repo: https://releases.rancher.com/server-charts/stable
    # -- Chart name
    name: rancher
    # -- Chart version
    version: 2.6.8
  values:
    # -- Rancher replicas
    replicas: 1
    # -- Only for bootstrapp, if the application is exposed consider changing it
    bootstrapPassword: changeme
    # -- Additionnal CA Bundle b64encoded
    caBundle: null
    ingress:
      # -- Enable Rancher ingress UI
      enabled: false
      # -- Rancher ingress name or path (weither it is an ingress wildcard or domain)
      name: rancher

uxp:
  # -- Enable Universal Crossplane chart
  enabled: false
  # -- Destination namespace
  namespace: upbound-system
  chart:
    # -- Helm repository
    repo: https://charts.upbound.io/stable
    # -- Chart name
    name: universal-crossplane
    # -- Chart version
    version: 1.10.1-up.1
  values: {}

# Monitoring

monitoring:
  # -- Monitoring destination namespace
  namespace: monitoring
  blackboxExporter:
    # -- Enable Blackbox exporter chart
    enabled: false
    chart:
      # -- Helm repository
      repo: https://prometheus-community.github.io/helm-charts
      # -- Chart name
      name: prometheus-blackbox-exporter
      # -- Chart version
      version: "5.8.2"
    values:
      # -- Enable prometheus default Prometheus rules
      enablePrometheusRules: true
      # -- Enable a Grafana specific dashboard, you will need to have Grafana enabled
      enableGrafanaDashboard: true
      # -- Create Url get configs accepted code are `200` & `403` (If you are using authentication)
      scrapeUrls: []
  discord:
    # -- Enable Discord alerting hooks, you will need to enable Prometheus & Alertmanager as well
    enabled: false
    chart:
      # -- Helm repository
      repo: https://masgustavos.github.io/helm
      # -- Chart name
      name: alertmanager-discord
      # -- Chart version
      version: "0.0.6"
    values:
      # -- Roles to mention in discord you can obtain the id by typing `\@Role_Name` in discord's chat
      rolesToMention: []
      # -- Channels list, watch section below for more informations
      channels: {}
  fio:
    # -- Enable Fio chart you will need to enable Prometheus as well
    enabled: false
    chart:
      # -- Helm repository (This own repository)
      repo: https://github.com/panzouh/argo-repository.git
      # -- Chart path
      path: charts/fio
      # -- Chart target revision, using `HEAD` allow you to use the same version of your cluster spec
      targetRevision: HEAD
    values:
      # -- Enable Fio exporter on the controll plane, by default Prometheus scraping is enabled
      installOnControllPlane: true
      # --fio Enable a Grafana specific dashboard, you will need to have Grafana enabled
      enableGrafanaDashboard: true
  goldpinger:
    # -- Enable Goldpinger chart
    enabled: false
    chart:
      # -- Helm repository
      repo: https://okgolove.github.io/helm-charts
      # -- Chart name
      name: goldpinger
      # -- Chart version
      version: "5.1.0"
    values:
      # -- Enable prometheus default Prometheus rules (not ready yet)
      enablePrometheusRules: true
      # -- Enable a Grafana specific dashboard, you will need to have Grafana enabled
      enableGrafanaDashboard: true
  grafana:
    # -- Enable Grafana chart
    enabled: false
    chart:
      # -- Helm repository
      repo: https://grafana.github.io/helm-charts
      # -- Chart name
      name: grafana
      # -- Chart version
      version: "6.44.10"
    values:
      auth:
        # -- Can be either raw or vault in order to pull password from Vault, you will need to enable AVP in ArgoCD with `.Values.argocd.values.plugins.avp.enabled=true`
        passwordType: raw
        # -- Grafana default admin username, only for raw type :warning: insecure :warning
        adminUser: "admin"
        # -- Grafana default admin password, only for raw type :warning: insecure :warning:
        adminPassword: "changeme"
        # -- Grafana username and password path on Vault if your kv-v2 path is `avp`, your avp path will be `avp/data/grafana` in order to put secrets here you should pass `vault kv put avp/grafana username=admin password=changeme`, only for `passwordType: vault`
        avpPath: "avp/data/grafana"
        # -- Configure username key in vault kv-v2 secret, only for `passwordType: vault`
        userKey: username
        # -- Configure password key in vault kv-v2 secret, only for `passwordType: vault`
        passwordKey: password
      # -- Grafana PVC size, you will need to define a StorageClass in `default.storageClass`
      pvcSize: 10Gi
      ingress:
        # -- Enable Grafana UI ingress
        enabled: true
        # -- Grafana ingress name or path (weither it is an ingress wildcard or domain)
        name: grafana
      # -- Create Grafana custom dashoards (Json Formated), watch section bellow, you will also need to enable Prometheus as well :warning: Using this technique is not advised :warning:
      customDashboards: {}
      # -- Create Grafana Dashboard available on Grafana Net, watch section bellow, you will also need to enable Prometheus as well
      customDashboardsGNET: {}
  helmExporter:
    # -- Enable Helm Exporter chart
    enabled: false
    chart:
      # -- Helm repository
      repo: https://shanestarcher.com/helm-charts/
      # -- Chart name
      name: helm-exporter
      # -- Chart version
      version: 1.2.2+6766a95
    values:
      # -- Disable namespaces to watch
      disabledNamespace: null
      # -- Enable a Grafana specific dashboard, you will need to have Grafana enabled
      enableGrafanaDashboard: true
  prometheus:
    # -- Enable Prometheus chart
    enabled: false
    chart:
      # -- Helm repository
      repo: https://prometheus-community.github.io/helm-charts
      # -- Chart name
      name: prometheus
      # -- Chart version
      version: "15.10.3"
    values:
      rules:
        # -- Enable Prometheus rules watch preconfigured rules below
        preconfiguredEnabled: true
        # -- Create Prometheus custom rules
        customs: ""
      alertmanager:
        # -- Enable Alertmanager in the chart
        enabled: false
        # -- Alertmanager PVC size, you will need to define a StorageClass in `default.storageClass`
        pvcSize: "5Gi"
        # -- Alertmanager configuration file, example below
        configurationFile: {}
      kubeStateMetrics:
        # -- Enable kubeStateMetrics in the chart
        enabled: true
      # -- Enable extra configuration scrapes in the, watch section bellow for examples
      extraScrapeConfigs: []
      nodeExporter:
        # -- Enable nodeExporter in the chart
        enabled: true
      server:
        # -- Prometheus PVC size, you will need to define a StorageClass in `default.storageClass`
        pvcSize: "30Gi"
        # -- Prometheus data retention
        retention: 720h
        # -- Prometheus server extra args
        extraArgs: []
        # -- Node tolerations for scheduling Prometheus to nodes with taints [Kubernetes Documentation](https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/)
        tolerations: []
        # -- Node labels for prometheus pod assignment
        nodeSelector: {}
        ingress:
          # -- Enable Prometheus UI Ingress
          enabled: true
          # -- Prometheus ingress name or path (weither it is an ingress wildcard or domain)
          name: prometheus
          auth:
            # -- Can be `none`, `raw` (:warning: both insecure :warning:) `vault`
            type: raw
            # -- Basic auth username (only for `raw` type)
            username: admin
            # -- Basic auth password (only for `raw` type)
            password: changeme
            # -- Prometheus username and password path on Vault if your kv-v2 path is `avp`, your avp path will be `avp/data/prometheus` in order to pull secrets from Vault you should pass `vault kv put avp/prometheus htpasswd=<htpasswd-chain> htpasswd_plain_password=admin:changeme` (creating htpasswd_plain_password is not mandatory but recommended in order to find your username & password values), only for `auth.type: vault`, you will need to enable AVP in ArgoCD with `.Values.argocd.values.plugins.avp.enabled=true`
            avpPath: avp/data/prometheus
            # -- Configure password key in vault kv-v2 secret, only for `auth.type: vault`
            authKey: htpasswd
  prometheusMsTeams:
    # -- Enable Prometheus Ms Teams Alert chart, you will need to enable Prometheus & Alertmanager as well
    enabled: false
    chart:
      # -- Helm repository
      repo: https://prometheus-msteams.github.io/prometheus-msteams/
      # -- Chart name
      name: prometheus-msteams
      # -- Chart version
      version: "1.3.0"
    values:
      # -- Enable Prometheus scraping
      monitor: false
      # -- Hooks list, watch section below for more informations
      hooks: []

# Networking

ingress:
  ingressDefinition:
    ssl:
      # -- Enforce strictTls :warning: not working yet :warning:
      strictTLS: false
      # -- Force TLS certificate section
      enabled: true
    dns:
      # -- DNS declaration of your cluster can be `domain` or `wildcard`
      mode: wildcard
      # -- Cluster DNS wildcard entry, it generate this kind of urls : `https://prometheus.your-cluster.domain.tld`
      wildcard: your-cluster.domain.tld
      # -- Cluster DNS entry, it generate this kind of urls : `https://domain.tld/prometheus`
      domain: domain.tld
    # -- Node tolerations for scheduling ingress controller to nodes with taints [Kubernetes Documentation](https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/)
    tolerations: []
    # -- Node labels for controller pod assignment
    nodeSelector: {}
  traefik:
    # -- Enable Traefik chart, you should know that you can't activate Traefik & Nginx
    enabled: false
    chart:
      # -- Helm repository
      repo: https://helm.traefik.io/traefik
      # -- Chart name
      name: traefik
      # -- Chart version
      version: "10.24.0"
    values:
      # -- Enable prometheus metrics scraping, you will need to enable Prometheus as well
      monitor: false
      # -- Enable a Grafana specific dashboard, you will need to have Grafana enabled
      enableGrafanaDashboard: true
      # -- Allow to add ingress annotations manually
      ingressAnnotations: {}
      service:
        # -- Can be either Loadbalancer or NodePort
        type: LoadBalancer
        # -- Only for BareMetal support if you want to enforce Traefik's service IP
        LoadBalancerIps: []
  nginx:
    # -- Enable Nginx chart, you should know that you can't activate Traefik & Nginx
    enabled: false
    chart:
      # -- Helm repository
      repo: https://kubernetes.github.io/ingress-nginx
      # -- Chart name
      name: ingress-nginx
      # -- Chart version
      version: "4.1.4"
    values:
      # -- Enable prometheus metrics scraping, you will need to enable Prometheus as well
      monitor: false
      # -- Enable a Grafana specific dashboard, you will need to have Grafana enabled
      enableGrafanaDashboard: true
      # -- Allow to add ingress annotations manually
      ingressAnnotations: {}
      service:
        # -- Can be either Loadbalancer or NodePort
        type: LoadBalancer
        # -- Only for BareMetal support if you want to enforce Nginx's service IP
        LoadBalancerIps: []

certmanager:
  # -- Enable Cert-manager chart
  enabled: false
  # -- Destination namespace
  namespace: cert-manager
  chart:
    # -- Helm repository
    repo: https://charts.jetstack.io
    # -- Chart name
    name: cert-manager
    # -- Chart version
    version: "v1.10.0"
  values:
    # -- Enable prometheus metrics scraping, you will need to enable Prometheus as well
    monitor: false
    clusterIssuerLetsEncrypt:
      # -- Enable Let's encrypt cluster issuers
      enabled: false
      # -- Configure certificate expiracy notice notifications
      email: jdoe@domain.tld
      stagging:
        # -- Enable LetsEncrypt stagging issuer
        enabled: false
      production:
        # -- Enable Let's Encrypt production issuer
        enabled: false
    clusterIssuerVault:
      # -- Enable Vault cluster issuer
      enabled: false
      # -- Only if `vault.enabled=false` for external Vault support only
      vaultUrl: "https://your-vault.domain.tld"
      # -- Configure PKI Path to use
      pkiPath: pki_int/sign/example-domain-tld
      # -- base64 encoded caBundle PEM file
      caBundle: null
      # -- Vault access Token
      token: s.iyNUhq8Ov4hIAx6snw5mB2nL

# Security

kubernetesReplicator:
  # -- Enable Kubernetes replicator chart
  enabled: false
  # -- Destination namespace
  namespace: kubernetes-replicator
  chart:
    # -- Helm repository
    repo: https://helm.mittwald.de
    # -- Chart name
    name: kubernetes-replicator
    # -- Chart version
    version: "2.7.3"
  values:
    # -- Grant Kubernetes replicator controller admin cluster role binding
    grantClusterAdmin: true

vault:
  # -- Enable Vault chart
  enabled: false
  chart:
    # -- Helm repository
    repo: https://helm.releases.hashicorp.com
    # Chart name
    name: vault
    # Chart version
    version: "0.20.1"
  values:
    # -- Enable prometheus metrics scraping, you will need to enable Prometheus as well
    monitor: false
    ingress:
      # -- Enable Vault UI Ingress
      enabled: true
      # --  Vault ingress name or path (weither it is an ingress wildcard or domain)
      name: vault
    # -- Vault persistence size, you will need to define a StorageClass in `default.storageClass`
    pvcSize: "10Gi"
    # -- Enable Vault HA
    ha: false
    # -- Enable Vault agent injector
    injector: false

vaultSecrets:
  chart:
    # -- Helm repository (This own repository)
    repo: https://github.com/panzouh/argo-repository.git
    # -- Chart path
    path: charts/vault-secrets
    # -- Chart target revision, using `HEAD` allow you to use the same version of your cluster spec
    targetRevision: HEAD

userManagement:
  # -- Enable User Management chart
  enabled: false
  chart:
    # -- Helm repository (This own repository)
    repo: https://github.com/panzouh/argo-repository.git
    # -- Chart path
    path: charts/users
    # -- Chart target revision, using `HEAD` allow you to use the same version of your cluster spec
    targetRevision: HEAD
  values:
    # -- Create a Service account and a role if specified, if no role is specified default is namespace admin
    namespaceRoles: []
    # -- Create a Service account and associate it to a clusterrole, it does not support yet the creation of a cluster role so you have to use defaults cluster roles
    clusterRoles: []
    # -- Add allowed namespace to Argocd AppProject
    allowedNamespace: []

# Storage

minio:
  # -- Enable MinIO chart
  enabled: false
  # -- Destination namespace
  namespace: minio-system
  chart:
    # -- Helm repository
    repo: https://charts.min.io/
    # -- Chart name
    name: minio
    # -- Chart version
    version: "5.0.0"
  values:
    # -- MinIO deployment mode supported values are `standalone`, `distributed` `gateway`
    mode: standalone
    # -- Memory requests
    rMemory: 2Gi
    # -- CPU requests
    rCpu: 500m
    auth:
      # -- Can be either raw or vault in order to pull password from Vault, you will need to enable AVP in ArgoCD with `.Values.argocd.values.plugins.avp.enabled=true`
      passwordType: raw
      # -- Grafana default admin username, only for raw type :warning: insecure :warning
      adminUser: "admin"
      # -- Grafana default admin password, only for raw type :warning: insecure :warning:
      adminPassword: "changeme"
      # -- Grafana username and password path on Vault if your kv-v2 path is `avp`, your avp path will be `avp/data/grafana` in order to put secrets here you should pass `vault kv put avp/grafana username=admin password=changeme`, only for `passwordType: vault`
      avpPath: "avp/data/minio"
      # -- Configure username key in vault kv-v2 secret, only for `passwordType: vault`
      userKey: username
      # -- Configure password key in vault kv-v2 secret, only for `passwordType: vault`
      passwordKey: password
    # -- Add Buckets, watch section bellow
    buckets: []
    # -- Add policies, watch section bellow
    policies: []
    # -- Add users, watch section bellow
    users: []
    # -- MinIO persistence size, you will need to define a StorageClass in `default.storageClass`
    pvcSize: 5OGi
    # -- MinIO services type for console and api
    serviceType: ClusterIP
    ingress:
      api:
        # -- Enable MinIO API Ingress
        enabled: true
        # --  MinIO API ingress name or path (weither it is an ingress wildcard or domain)
        name: minio-api
      console:
        # -- Enable MinIO UI Ingress
        enabled: true
        # --  MinIO UI ingress name or path (weither it is an ingress wildcard or domain)
        name: minio-console
    # -- Enable prometheus metrics scraping, you will need to enable Prometheus as well
    monitor: false
